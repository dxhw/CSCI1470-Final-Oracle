{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating one-hot encodings from the dataset labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":924,"status":"ok","timestamp":1714693583892,"user":{"displayName":"Michelle Ding","userId":"05480671719146406257"},"user_tz":240},"id":"3lTv3w2SLoK1","outputId":"07903065-43ba-4ed6-fbd3-4ae1c26db468"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWvoogATLjyF"},"outputs":[],"source":["# dict contains file paths to tensorflow datasets created using preprocessing code\n","saved_data_paths = {\n","    \"test4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/wangtest\",\n","    \"wangtrain\":\"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/wangtrain\",\n","\n","    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test1\",\n","    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test2\",\n","    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test3\",\n","\n","    \"train1a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1a\",\n","    \"train1b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1b\",\n","    \"train1c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1c\",\n","\n","    \"train2a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2a\",\n","    \"train2b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2b\",\n","    \"train2c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2c\",\n","\n","    \"train3a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3a\",\n","    \"train3b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3b\",\n","    \"train3c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3c\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdOtb2oHFHOd"},"outputs":[],"source":["# paths to save onehot datasets to:\n","onehot_datapaths2 = {\n","    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test1\",\n","    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test2\",\n","    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test3\",\n","    \"test4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test4\",\n","\n","    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train1\",\n","    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train2\",\n","    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train3\",\n","    \"train4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train4\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83S8fjv24b_E"},"outputs":[],"source":["def load_dataset(dataset_name: str):\n","  path = saved_data_paths[dataset_name]\n","  dataset = tf.data.Dataset.load(path)\n","  print(\"Dataset\", dataset_name, \"loaded\")\n","  return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2wwKTwUEUoP"},"outputs":[],"source":["num_classes_dict = {\n","    \"train1\": 1777,\n","    \"train2\": 1656,\n","    \"train3\": 1628,\n","    \"train4\": 1588\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yICfbc1sz3D"},"outputs":[],"source":["def transform_labels(labels, num_classes):\n","    # Get unique labels and number of classes\n","    unique_labels = sorted(set(labels))\n","\n","    # Map each unique label to an integer in the range [0, num_classes - 1]\n","    label_map = {str(label): index for index, label in enumerate(unique_labels)}\n","\n","    print(\"Labels transformed\")\n","    return label_map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rn1bQwFclU66"},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import json\n","from tqdm import tqdm\n","\n","def get_one_hot_train_dataset(dataset_name, dataset, json_file):\n","    label_one_hot_dict = {}\n","    labels = []\n","    for item in dataset:\n","        _, label = item\n","        labels.append(label.numpy())\n","\n","    num_classes = num_classes_dict[dataset_name]\n","    transformed_label_dict = transform_labels(labels, num_classes)\n","\n","    # Create a directory for saving batches if it doesn't exist\n","    directory = '/content/drive/Shareddrives/DL_Final_Project/batches_tf'\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","    # Iterate over the dataset and save each batch\n","    batch_size = 5000\n","    current_batch = 0\n","    num_batches = len(dataset) // batch_size\n","    remaining_samples = len(dataset) % batch_size\n","    with tqdm(total=num_batches, desc=\"Saving batches\") as pbar:\n","        for batch_images, batch_labels in dataset.batch(batch_size):\n","            # Prepare the batch data\n","            batch_data = []\n","            for image, label in zip(batch_images, batch_labels):\n","                one_hot_encoding = tf.one_hot(\n","                    transformed_label_dict[str(tf.get_static_value(label))], num_classes)\n","                batch_data.append((image, one_hot_encoding))\n","\n","            # Convert the batch data to TensorFlow Dataset\n","            batch_tf_dataset = tf.data.Dataset.from_generator(\n","                lambda: batch_data,\n","                output_signature=(\n","                    tf.TensorSpec(shape=batch_images.shape[1:], dtype=batch_images.dtype),\n","                    tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)\n","                ))\n","\n","            # Save the batch as a TF dataset\n","            batch_file_path = os.path.join(directory, f\"{dataset_name}_batch_{current_batch}.tfdataset\")\n","            batch_tf_dataset.save(batch_file_path)\n","            pbar.update(1)\n","            current_batch += 1\n","\n","    print(\"Batches saved\")\n","\n","    # # Save labels and their one-hot encodings to JSON\n","    # json_path = os.path.join(directory, json_file)\n","    # with open(json_path, 'w') as json_file:\n","    #     json.dump(label_one_hot_dict, json_file)\n","    # print(\"JSON written\")\n","\n","    return transformed_label_dict, num_classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cG-bblBkCoLf"},"outputs":[],"source":["def get_one_hot_test_dataset(dataset_name, transformed_label_dict, num_classes, dataset):\n","    new_dataset = []\n","    for image, label in dataset:\n","        one_hot_encoding = tf.one_hot(transformed_label_dict[str(tf.get_static_value(label))], num_classes)\n","        new_dataset.append((image, one_hot_encoding))\n","\n","    # Convert the new dataset to TensorFlow Dataset\n","    tf_dataset = tf.data.Dataset.from_generator(lambda: new_dataset, output_signature=(\n","        tf.TensorSpec(shape=image.shape, dtype=image.dtype),\n","        tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)\n","    ))\n","\n","    return tf_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKC-U9f626rd"},"outputs":[],"source":["concat_save_path = {\n","    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/concat_datasets/train1\",\n","    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/concat_datasets/train2\",\n","    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/concat_datasets/train3\",\n","    \"train4\": \"/content/drive/Shareddrives/DL_Final_Project/concat_datasets/train4\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXUw9oSCLm_e"},"outputs":[],"source":["# ======================= LOAD DATASETS =======================\n","'''\n","save training data\n","@train_name: name of training set\n","@test_name: name of test set\n","'''\n","def save_group(train_name, test_name):\n","  print(\"========= TRAIN SET ========\")\n","  print(train_name)\n","  print(\"----------------------------\")\n","\n","  # ================== LOADING DATASETS ==================\n","  train_dataset = tf.data.Dataset.load(concat_save_path[train_name])\n","  print(train_name, \"concat loaded\")\n","\n","  # ================== ONEHOT ENCODING ==================\n","  trans_dict, num_classes = get_one_hot_train_dataset(train_name, train_dataset, train_name+\".json\")\n","  print(\"one hot data loaded\")\n","  print(train_name, \"num classes:\", num_classes)\n","\n","  # ================== SAVING DATASET TOGETHER ==================\n","  print(train_name, \"saved\")\n","\n","  # ================== DONE ==================\n","  print(train_name, \"successfully processed!\")\n","  # -----------------------------------------------------\n","  print(\"========= TEST SET =========\")\n","  print(test_name)\n","  print(\"----------------------------\")\n","  # ================== LOADING DATASET ==================\n","  test_dataset = load_dataset(test_name)\n","\n","  # ================== ONEHOT ENCODING ==================\n","  onehot_testdataset = get_one_hot_test_dataset(test_name, trans_dict, num_classes, test_dataset)\n","  print(test_name, \"one hot created\")\n","\n","  # ================== SAVING DATASET TOGETHER ==================\n","  onehot_testdataset.save(onehot_datapaths2[test_name])\n","  print(test_name, \"saved\")\n","\n","  # ================== DONE ==================\n","  print(test_name, \"successfully processed!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":555165,"status":"ok","timestamp":1714694149374,"user":{"displayName":"Michelle Ding","userId":"05480671719146406257"},"user_tz":240},"id":"rMvCp59tOzaW","outputId":"083c129b-9400-4b6e-d432-83cef575d173"},"outputs":[{"name":"stdout","output_type":"stream","text":["========= TRAIN SET ========\n","train4\n","----------------------------\n","train4 concat loaded\n","Labels transformed\n"]},{"name":"stderr","output_type":"stream","text":["Saving batches: 13it [05:22, 24.77s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Batches saved\n","one hot data loaded\n","train4 num classes: 1588\n","train4 saved\n","train4 successfully processed!\n","========= TEST SET =========\n","test4\n","----------------------------\n","Dataset test4 loaded\n","test4 one hot created\n","test4 saved\n","test4 successfully processed!\n"]}],"source":["# save_group(\"train1\", \"test1\")\n","# save_group(\"train2\", \"test2\")\n","# save_group(\"train3\", \"test3\")\n","save_group(\"train4\", \"test4\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.13 ('csci1470')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13"},"vscode":{"interpreter":{"hash":"9a7e07fcbaf4af9252e1c87bf108cb597e6cdfc24e4948d18c80253779dac4ac"}}},"nbformat":4,"nbformat_minor":0}
