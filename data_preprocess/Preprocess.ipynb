{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This is the preprocessing code used for our image/label preprocessing "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1220,"status":"ok","timestamp":1714681477908,"user":{"displayName":"Michelle Ding","userId":"10954034203545033157"},"user_tz":240},"id":"7q4Wq4B6eWeY","outputId":"e42cd94b-c2cb-4963-c6bc-2105a1ad43fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61142,"status":"ok","timestamp":1714681539048,"user":{"displayName":"Michelle Ding","userId":"10954034203545033157"},"user_tz":240},"id":"38q2L_qYl4Wc","outputId":"69399860-3712-4c83-ec15-d4dc7a396769"},"outputs":[],"source":["!unzip /content/drive/Shareddrives/DL_Final_Project/HUST-OBS.zip > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13323,"status":"ok","timestamp":1714681552369,"user":{"displayName":"Michelle Ding","userId":"10954034203545033157"},"user_tz":240},"id":"XbCaoJt-__6s","outputId":"4655f7d0-f29b-434f-a346-cccc535876fc"},"outputs":[],"source":["!pip install tf-models-official"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0s7jRk7wePt0"},"outputs":[],"source":["import json\n","import os\n","from tqdm import tqdm\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"svsDmNJ2PZxg"},"outputs":[],"source":["# !pip install --upgrade tensorflow keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxHptITTgY9v"},"outputs":[],"source":["import random\n","from datetime import datetime\n","import cv2\n","import numpy as np\n","import math\n","import argparse\n","import pandas as pd\n","import tensorflow as tf\n","import csv\n","import matplotlib.pyplot as plt\n","import keras\n","import tensorflow_models as tfm"]},{"cell_type":"markdown","metadata":{"id":"DIFfEsNiWIMX"},"source":["Datasplit:\n","\n","1: TRAIN: ['H', 'X', 'L', 'Y'] TEST: ['G']\n","\n","2: TRAIN: ['H', 'G', 'L', 'Y'] TEST: ['X']\n","\n","3: TRAIN: ['H', 'X', 'G'] TEST: ['L', 'Y']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAp0NldWbo1I"},"outputs":[],"source":["'''\n","adding salt & pepper noise to dataset\n","CREDIT: Wang et al. HUST-OBS data preprocessing\n","\n","NOTE: In order to create comparable results, we need to\n","do the same preprocessing steps on the dataset\n","'''\n","def salt_and_pepper_noise(image):\n","  if np.random.random() < 0.5:\n","      image1 = np.array(image)\n","\n","      # add noise\n","      salt_vs_pepper_ratio = np.random.uniform(0, 0.4)\n","      amount = np.random.uniform(0, 0.006)\n","      num_salt = np.ceil(amount * image1.size / 3 * salt_vs_pepper_ratio)\n","      num_pepper = np.ceil(amount * image1.size / 3 * (1.0 - salt_vs_pepper_ratio))\n","\n","      # Generate at random locations\n","      coords_salt = [np.random.randint(0, i - 1, int(num_salt)) for i in image1.shape]\n","      coords_pepper = [np.random.randint(0, i - 1, int(num_pepper)) for i in image1.shape]\n","\n","      # image1[coords_salt] = 255\n","      image1[coords_salt[0], coords_salt[1], :] = 255\n","      image1[coords_pepper[0], coords_pepper[1], :] = 0\n","      image = Image.fromarray(image1)\n","\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k1n0h13cdmJ"},"outputs":[],"source":["'''\n","erode_and_dialate image for noise removal, segmentation, and feature extraction\n","CREDIT: Wang et al. HUST-OBS data preprocessing\n","\n","NOTE: In order to create comparable results, we need to\n","do the same preprocessing steps on the dataset\n","'''\n","def erode_and_dialate(image):\n","  # Generate a random number between 0 and 2\n","  random_value = random.random() * 3\n","\n","  if random_value < 1:  # 1/3 probability of performing addition operation\n","      he = random.randint(1, 3)\n","      kernel = np.ones((he, he), np.uint8)\n","      image = cv2.erode(image, kernel, iterations=1)\n","  elif random_value < 2:  # 1/3 probability of performing division operation\n","      he = random.randint(1, 3)  # Generate a random integer between 1 and 10 as the divisor\n","      kernel = np.ones((he, he), np.uint8)\n","      image = cv2.dilate(image, kernel, iterations=1)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FihHUAEiotLq"},"outputs":[],"source":["class RandomGaussianBlur(object):\n","    def __init__(self, p=0.5, min_kernel_size=3, max_kernel_size=15, min_sigma=0.1, max_sigma=1.0):\n","        self.p = p\n","        self.min_kernel_size = min_kernel_size\n","        self.max_kernel_size = max_kernel_size\n","        self.min_sigma = min_sigma\n","        self.max_sigma = max_sigma\n","\n","    def __call__(self, img):\n","        if random.random() < self.p and self.min_kernel_size < self.max_kernel_size:\n","            kernel_size = random.randrange(self.min_kernel_size, self.max_kernel_size + 1, 2)\n","            sigma = random.uniform(self.min_sigma, self.max_sigma)\n","            return tfm.vision.augment.gaussian_filter2d(img, kernel_size, sigma)\n","        else:\n","            return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkmWjNoVeJzp"},"outputs":[],"source":["def pad_with_white(image, xl, yl, xr, yr):\n","  # white is RGB (255, 255, 255), so we want to pad with 255\n","  # the dimensions of the image are (height, width, channels)\n","  paddings = [[yl, yr], [xl, xr], [0, 0]]\n","  image = tf.pad(image, paddings, mode='CONSTANT', constant_values=255)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9x7vhOxEqKa"},"outputs":[],"source":["class ColorJitter(object):\n","  def __init__(self, brightdelta, contrastdelta, satdelta, huedelta):\n","    self.brightdelta = brightdelta\n","    self.contrastdelta = contrastdelta\n","    self.satdelta = satdelta\n","    self.huedelta = huedelta\n","\n","  def __call__(self, image):\n","    image = tf.image.random_brightness(image, self.brightdelta)\n","    image = tf.image.random_contrast(image, max(0, 1 - self.contrastdelta), 1 + self.contrastdelta)\n","    image = tf.image.random_saturation(image, max(0, 1 - self.satdelta), 1 + self.satdelta)\n","    image = tf.image.random_hue(image, self.huedelta)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8WPAIp0DAFn"},"outputs":[],"source":["def random_apply(image, transforms, p):\n","  if random.random() <= p:\n","    for transform in transforms:\n","      image = transform(image)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLtrRtNcityN"},"outputs":[],"source":["def tensorflow_normalize(image, mean, std):\n","    image = tf.convert_to_tensor(image, dtype=tf.float32)\n","    image = (image - mean) / std\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bc2wA4FZ9-f"},"outputs":[],"source":["'''\n","process_image_train converts a png to a tensor\n","'''\n","def process_image_train(image):\n","  # Checks if image is grayscale and converts to RGB\n","  if image.mode == 'L':\n","        image = image.convert('RGB')\n","\n","  # Resize image to 72 x 72\n","  w, h = image.size\n","  if w > h:\n","      x = 72\n","      y = round(h / w * 72)\n","  # x, y = 72,72\n","  else:\n","      y = 72\n","      x = round(w / h * 72)\n","\n","  # Reshape to desired x & y of 129 x 129 pixels\n","  sizey, sizex = 129, 129\n","  if y < 128:\n","      while sizey > 128 or sizey < 16:\n","          sizey = round(random.gauss(y, 30))\n","  if x < 128:\n","      while sizex > 128 or sizex < 16:\n","          sizex = round(random.gauss(x, 30))\n","\n","  dx = 128 - sizex\n","  dy = 128 - sizey\n","\n","  if dx > 0:\n","      xl = -1\n","      while xl > dx or xl < 0:\n","          xl = round(dx / 2)\n","          xl = round(random.gauss(xl, 10))\n","  else:\n","      xl = 0\n","  if dy > 0:\n","      yl = -1\n","      while yl > dy or yl < 0:\n","          yl = round(dy / 2)\n","          yl = round(random.gauss(yl, 10))\n","  else:\n","      yl = 0\n","\n","  yr = dy - yl\n","  xr = dx - xl\n","\n","  # Image processing\n","  image = salt_and_pepper_noise(image)\n","  image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n","  image = erode_and_dialate(image)\n","  image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","  random_gaussian_blur = RandomGaussianBlur()\n","  image = random_gaussian_blur(image)\n","  image = tf.image.resize(image, (sizey, sizex))\n","  image = tf.image.random_flip_left_right(image)\n","  image = pad_with_white(image, xl, yl, xr, yr)\n","  image = tf.keras.layers.RandomRotation(factor=15/(180 * math.pi), fill_mode='constant', fill_value=255)(image)\n","  mean = [0.85233593, 0.85246795, 0.8517555]\n","  std = [0.31232414, 0.3122127, 0.31273854]\n","  image = tensorflow_normalize(image, mean, std)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-01RftVvJ1z"},"outputs":[],"source":["'''\n","process_image_test converts a png to a tensor\n","'''\n","def process_image_test(image):\n","  # Checks if image is grayscale and converts to RGB\n","  if image.mode == 'L':\n","        image = image.convert('RGB')\n","\n","  # Resize image to 72 x 72\n","  w, h = image.size\n","  if w > h:\n","      dy = w - h\n","      yl = round(dy / 2)\n","      yr = dy - yl\n","      image = pad_with_white(image, 0, yl, 0, yr)\n","  else:\n","      dx = h - w\n","      xl = round(dx / 2)\n","      xr = dx - xl\n","      image = pad_with_white(image, xl, 0, xr, 0)\n","\n","  image = tf.image.resize(image, (128, 128))\n","  mean = [0.85233593, 0.85246795, 0.8517555]\n","  std = [0.31232414, 0.3122127, 0.31273854]\n","  image = tensorflow_normalize(image, mean, std)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYGc238Sy35t"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def preprocess(path: str, process_type: str):\n","    assert process_type in [\"train\", \"test\"] # check if preprocess type is train/test\n","\n","    with open(path, newline='') as csvfile:\n","        reader = csv.reader(csvfile, delimiter=',')\n","\n","        # process labels\n","        inputs = []\n","        labels = []\n","\n","        # Count the total number of rows excluding the header\n","        total_rows = sum(1 for _ in reader) - 1  # Exclude the header row\n","        csvfile.seek(0)  # Reset the file pointer\n","\n","        # process images\n","        header = True\n","        for row in tqdm(reader, total=total_rows, desc=f'Processing {process_type} data'):\n","            if header is True:\n","                header = False\n","            else:\n","                try:\n","                  label = int(row[0]) # get labels\n","                  image_path = row[1] # get images\n","                  image = Image.open(image_path) # open image\n","                except:\n","                  print(\"error in\", row, \"with label\", label, \"image\", image_path)\n","\n","                if (process_type==\"train\"):\n","                    image = process_image_train(image) # process image for train\n","\n","                if (process_type == \"test\"):\n","                    image = process_image_test(image) # process image for test\n","\n","                # update the labels & images lists\n","                labels.append(label) # add label to label list\n","                inputs.append(image)\n","\n","    labels = tf.convert_to_tensor(labels)\n","    print(labels.shape)\n","\n","    # labels = tf.convert_to_tensor(np.array(labels))\n","    dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n","    return dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYcCO9MHUld8"},"outputs":[],"source":["# train or test\n","process_type = {\n","    \"mock\": \"train\",\n","    \"wangtest\": \"test\",\n","    \"wangtrain\": \"train\",\n","    \"train1\": \"train\",\n","    \"train2\": \"train\",\n","    \"train3\": \"train\",\n","    \"test1\": \"test\",\n","    \"test2\": \"test\",\n","    \"test3\": \"test\",\n","    \"train1a\": \"train\",\n","    \"train1b\": \"train\",\n","    \"train1c\": \"train\",\n","    \"train2a\": \"train\",\n","    \"train2b\": \"train\",\n","    \"train2c\": \"train\",\n","    \"train3a\": \"train\",\n","    \"train3b\": \"train\",\n","    \"train3c\": \"train\",\n","    \"train4a\": \"train\",\n","    \"train4b\": \"train\",\n","    \"train4c\": \"train\",\n","    \"train4d\": \"train\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FC9iMCUtsQCj"},"outputs":[],"source":["# Storing file paths to train & test csv datasets:\n","file_paths = {\n","    \"mock\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/mock.csv\",\n","    \"wangtest\":\"/content/drive/Shareddrives/DL_Final_Project/DATA/wang_test.csv\",\n","    \"wangtrain\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/wang_train.csv\",\n","    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/train1-HXLY.csv\",\n","    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/train2-HGLY.csv\",\n","    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/train3-HXG.csv\",\n","    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/test1-G.csv\",\n","    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/test2-X.csv\",\n","    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/test3-LY.csv\",\n","\n","    \"train1a\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN1/partition_1.csv\",\n","    \"train1b\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN1/partition_2.csv\",\n","    \"train1c\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN1/partition_3.csv\",\n","\n","    \"train2a\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN2/partition_1.csv\",\n","    \"train2b\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN2/partition_2.csv\",\n","    \"train2c\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN2/partition_3.csv\",\n","\n","    \"train3a\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN3/partition_1.csv\",\n","    \"train3b\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN3/partition_2.csv\",\n","    \"train3c\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN3/partition_3c.csv\",\n","\n","    \"train4a\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN4/partition_1.csv\",\n","    \"train4b\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN4/partition_2.csv\",\n","    \"train4c\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN4/partition_3.csv\",\n","    \"train4d\": \"/content/drive/Shareddrives/DL_Final_Project/DATA/TRAIN4/partition_4.csv\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5L5NziE-TPnb"},"outputs":[],"source":["saved_data_paths = {\n","    \"mock\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/mock\",\n","    \"wangtest\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/wangtest\",\n","    \"wangtrain\":\"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/wangtrain\",\n","    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1\",\n","    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2\",\n","    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3\",\n","    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test1\",\n","    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test2\",\n","    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test3\",\n","\n","    \"train1a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1a\",\n","    \"train1b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1b\",\n","    \"train1c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1c\",\n","\n","    \"train2a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2a\",\n","    \"train2b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2b\",\n","    \"train2c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2c\",\n","\n","    \"train3a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3a\",\n","    \"train3b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3b\",\n","    \"train3c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3c\",\n","\n","    \"train4a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train4a\",\n","    \"train4b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train4b\",\n","    \"train4c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train4c\",\n","    \"train4d\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train4d\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"m3qDsH3bl-Cn","outputId":"53433fb3-c7ef-4bf6-e12f-e1dc8c2c81ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["==========================\n","train4c\n","--------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing train data: 15415it [11:43, 21.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(15414,)\n","Dataset train4c saved successfully\n"]}],"source":["# preprocess takes in\n","# 1) file path (see file_paths dict)\n","# 2) \"train\" or \"test\" mode of preprocess\n","key = \"train4c\" # we need to do train1a, train1b, train1c, train2a, train2b, train2c, train3a, train3b, train3c\n","print(\"==========================\")\n","print(key)\n","print(\"--------------------------\")\n","dataset = preprocess(file_paths[key], process_type[key])\n","save_path = saved_data_paths[key]\n","try:\n","    dataset.save(save_path)\n","    print(\"Dataset\", key, \"saved successfully\")\n","except Exception as e:\n","    print(\"Error saving dataset:\", e)\n"]},{"cell_type":"markdown","metadata":{"id":"cpq6WgFvQ8cJ"},"source":["##Testing (this section sees if pytorch & tensorflow are returning the same during reimplementation)\n","We need to make sure that our preprocessing is the same as Wang et al 2024 in order to make our\n","results comparable "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9XfjWoJhB6DW"},"outputs":[],"source":["test_image = \"/content/drive/Shareddrives/DL_Final_Project/HUST-OBS/deciphered/0005/G_0005_甲1170合31823無名組.png\"\n","image = Image.open(test_image)\n","if image.mode == 'L':\n","    image = image.convert('RGB')\n","image_width, image_height = image.size\n","if image_width > image_height:\n","    x = 72\n","    y = round(image_height / image_width * 72)\n","# x, y = 72,72\n","else:\n","    y = 72\n","    x = round(image_width / image_height * 72)\n","sizey, sizex = 129, 129\n","if y < 128:\n","    while sizey > 128 or sizey < 16:\n","        sizey = round(random.gauss(y, 30))\n","if x < 128:\n","    while sizex > 128 or sizex < 16:\n","        sizex = round(random.gauss(x, 30))\n","dx = 128 - sizex  \n","dy = 128 - sizey\n","if dx > 0:\n","    xl = -1\n","    while xl > dx or xl < 0:\n","        xl = round(dx / 2)\n","        xl = round(random.gauss(xl, 10))\n","else:\n","    xl = 0\n","if dy > 0:\n","    yl = -1\n","    while yl > dy or yl < 0:\n","        yl = round(dy / 2)\n","        yl = round(random.gauss(yl, 10))\n","else:\n","    yl = 0\n","yr = dy - yl\n","xr = dx - xl\n","image = salt_and_pepper_noise(image)\n","image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n","image = erode_and_dialate(image)\n","image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6PfsL6B8B9_z"},"outputs":[],"source":["from torchvision import transforms\n","def test(img, a=None, b=None, c=None, d=None):\n","  torch_img = transforms.Resize((sizey,sizex))(img)\n","  torch_img = transforms.Pad([xl, yl, xr, yr], fill=(255, 255, 255), padding_mode='constant')(torch_img)\n","  #torch_img = transforms.RandomRotation(degrees=(15, 15), center=(round(64), round(64)), fill=(255, 255, 255))(torch_img)\n","  torch_img = transforms.RandomGrayscale(p=1)(torch_img)\n","  blur = RandomGaussianBlur()\n","  #tf_img = blur(img)\n","  tf_img = tf.image.resize(img, (sizey, sizex))\n","  tf_img = pad_with_white(tf_img, xl, yl, xr, yr)\n","  #tf_img = tf.keras.layers.RandomRotation(factor=(15/(180 * math.pi), 15/(180 * math.pi)), fill_mode='constant', fill_value=255)(tf_img)\n","  #tf_img = random_apply(tf_img, [ColorJitter(0.4, 0.4, 0.4, 0.1)], 0.8)\n","  tf_img = random_apply(tf_img, [tf.image.rgb_to_grayscale], 1)\n","  return torch_img, tf_img"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"m6MBIVjqB_zr"},"outputs":[],"source":["# from PIL import ImageChops"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6Lz08_k8CB9I"},"outputs":[],"source":["#display(image)\n","a, b = test(image)\n","b = tf.keras.utils.array_to_img(b.numpy())\n","print(a)\n","display(a)\n","display(b)\n","print(b.size)\n","\n","diff = ImageChops.difference(a, b)\n","print(a.size)\n","print(b.size)\n","display(diff)\n","\n","\n","if diff.getbbox():\n","  #The images are inherently going to be a bit different, I think just converting to and from torch and tf changes them\n","  # but make sure the diff image (the black one with white bits) is mostly similar\n","    print(\"images are different\")\n","else:\n","    print(\"images are the same\")\n","\n","a = np.array(a)\n","b = np.array(b)\n","\n","# Write the array to disk\n","with open('/content/drive/Shareddrives/DL_Final_Project/torchout.txt', 'w') as outfile:\n","    # I'm writing a header here just for the sake of readability\n","    # Any line starting with \"#\" will be ignored by numpy.loadtxt\n","    outfile.write('# Array shape: {0}\\n'.format(a.shape))\n","\n","    # Iterating through a ndimensional array produces slices along\n","    # the last axis. This is equivalent to data[i,:,:] in this case\n","    for data_slice in a:\n","\n","        # The formatting string indicates that I'm writing out\n","        # the values in left-justified columns 7 characters in width\n","        # with 2 decimal places.\n","        np.savetxt(outfile, data_slice, fmt='%-7.2f')\n","\n","        # Writing out a break to indicate different slices...\n","        outfile.write('# New slice\\n')\n","\n","with open('/content/drive/Shareddrives/DL_Final_Project/tfout.txt', 'w') as outfile:\n","    # I'm writing a header here just for the sake of readability\n","    # Any line starting with \"#\" will be ignored by numpy.loadtxt\n","    outfile.write('# Array shape: {0}\\n'.format(b.shape))\n","\n","    # Iterating through a ndimensional array produces slices along\n","    # the last axis. This is equivalent to data[i,:,:] in this case\n","    for data_slice in b:\n","\n","        # The formatting string indicates that I'm writing out\n","        # the values in left-justified columns 7 characters in width\n","        # with 2 decimal places.\n","        np.savetxt(outfile, data_slice, fmt='%-7.2f')\n","\n","        # Writing out a break to indicate different slices...\n","        outfile.write('# New slice\\n')\n","\n","#open a file and write to it and then get the diff?\n","# with open('/content/drive/Shareddrives/DL_Final_Project/upload_check.txt', 'w') as g:\n","#   a = np.array(a)\n","#   b = np.array(b)\n","#   np.savetxt('/content/drive/Shareddrives/DL_Final_Project/torchout.txt', a)\n","#   np.savetxt('/content/drive/Shareddrives/DL_Final_Project/tfout.txt', b)\n","  # g.write(\"torch\\n\")\n","  # g.write(str(np.array(a).to_list()))\n","  # g.write(\"\\ntensorflow\\n\")\n","  # g.write(str(np.array(b).to_list()))\n","# print(np.array(a))\n","# print(\"\\n\")\n","# print(np.array(b))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sVHj_kNpbomL"},"outputs":[],"source":["# TEST NORMALIZATION\n","import torch\n","import torchvision.transforms as transforms\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","def pytorch_normalize(image):\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.85233593, 0.85246795, 0.8517555], [0.31232414, 0.3122127, 0.31273854])\n","    ])\n","    return transform(image)\n","\n","def tensorflow_normalize(image, mean, std):\n","    image = tf.convert_to_tensor(image, dtype=tf.float32)\n","    image = (image - mean) / std\n","    return image\n","\n","# Define image dimensions\n","width = 100\n","height = 100\n","\n","# Generate a gradient for each color channel\n","channel_r = np.linspace(0, 1, width * height).reshape(height, width)\n","channel_g = np.linspace(1, 0, width * height).reshape(height, width)\n","channel_b = np.zeros((height, width))  # Constant zero for blue channel\n","\n","# Combine channels to create a color image\n","image = np.stack([channel_r, channel_g, channel_b], axis=-1)\n","\n","torch_normalized = pytorch_normalize(image)\n","\n","# Normalize with TensorFlow\n","mean = [0.85233593, 0.85246795, 0.8517555]\n","std = [0.31232414, 0.3122127, 0.31273854]\n","tf_normalized = tensorflow_normalize(image, mean, std)\n","\n","# print(torch_normalized)\n","# print(\"...\")\n","# print(tf_normalized)\n","\n","# Check if the results are the same\n","assert np.allclose(torch_normalized.permute(1, 2, 0).numpy(), tf_normalized.numpy(), atol=1e-5, rtol=1e-3)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6qETlT69jPtJ"},"outputs":[],"source":["import torch\n","import tensorflow as tf\n","import numpy as np\n","\n","# Create a sample NumPy array\n","np_array = np.array([1, 2, 3, 4, 5])\n","\n","# Convert the NumPy array to a tensor in PyTorch\n","torch_tensor = torch.from_numpy(np_array)\n","\n","# Convert the NumPy array to a tensor in TensorFlow\n","tf_tensor = tf.convert_to_tensor(np_array)\n","\n","# Check if the results are the same\n","print(tf_tensor)\n","print(torch_tensor)\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.13 ('csci1470')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13"},"vscode":{"interpreter":{"hash":"9a7e07fcbaf4af9252e1c87bf108cb597e6cdfc24e4948d18c80253779dac4ac"}}},"nbformat":4,"nbformat_minor":0}
