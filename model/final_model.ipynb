{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data description:\n",
        "> mock: mocked dataset with a small subset of images & labels \\\n",
        "> wangtest: original paper test set \\\n",
        "> wangtrain: original paper train set \\\n",
        "> train1 (split into a,b,c): ['H', 'X', 'L', 'Y'] \\\n",
        "> test 1: ['G'] \\\n",
        "> train2 (split into a,b,c): ['H', 'G', 'L', 'Y'] \\\n",
        "> test2: ['X'] \\\n",
        "> train3 (split into a,b,c): ['H', 'X', 'G'] \\\n",
        "> test3: ['L', 'Y']\n"
      ],
      "metadata": {
        "id": "eivtMmniblLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RTm990p5VwaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cebe3a9-37cd-4479-fedf-ac8aa64bcaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_paths = {\n",
        "    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/shuffle/train1\",\n",
        "    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/FINAL_DATASETS/test1\",\n",
        "    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/shuffle/train2\",\n",
        "    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/FINAL_DATASETS/test2\",\n",
        "    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/shuffle/train3\",\n",
        "    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/FINAL_DATASETS/test3\",\n",
        "    \"train4\": \"/content/drive/Shareddrives/DL_Final_Project/FINAL_DATASETS/train4\",\n",
        "    \"test4\": \"/content/drive/Shareddrives/DL_Final_Project/FINAL_DATASETS/test4\"\n",
        "}"
      ],
      "metadata": {
        "id": "kDhQHR4Ws9Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_dict = {\n",
        "    \"group1\" :  \"/content/drive/Shareddrives/DL_Final_Project/checkpoints1_new\",\n",
        "    \"group2\" :  \"/content/drive/Shareddrives/DL_Final_Project/checkpoints2\",\n",
        "    \"group3\" :  \"/content/drive/Shareddrives/DL_Final_Project/checkpoints3\",\n",
        "    \"group4\" :  \"/content/drive/Shareddrives/DL_Final_Project/checkpoints4\"\n",
        "}"
      ],
      "metadata": {
        "id": "KsCzT9HXK_W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contains num_classes for each dataset -- test & train are the same\n",
        "num_classes_dict = {\n",
        "    \"train1\": 1777,\n",
        "    \"train2\": 1656,\n",
        "    \"train3\": 1628,\n",
        "    \"train4\": 1588\n",
        "}"
      ],
      "metadata": {
        "id": "LF0f3kW_YBNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Returns the args for the group\n",
        "num_classes, train_data, test_data, directory\n",
        "'''\n",
        "def get_group_args(group):\n",
        "  assert group in [1,2,3,4]\n",
        "  if group==1:\n",
        "    num_classes = num_classes_dict[\"train1\"]\n",
        "    train_data = dataset_paths[\"train1\"]\n",
        "    test_data = dataset_paths[\"test1\"]\n",
        "    directory = directory_dict[\"group1\"]\n",
        "  if group==2:\n",
        "    num_classes = num_classes_dict[\"train2\"]\n",
        "    train_data = dataset_paths[\"train2\"]\n",
        "    test_data = dataset_paths[\"test2\"]\n",
        "    directory = directory_dict[\"group2\"]\n",
        "  if group == 3:\n",
        "    num_classes = num_classes_dict[\"train3\"]\n",
        "    train_data = dataset_paths[\"train3\"]\n",
        "    test_data = dataset_paths[\"test3\"]\n",
        "    directory = directory_dict[\"group3\"]\n",
        "  if group == 4:\n",
        "    num_classes = num_classes_dict[\"train4\"]\n",
        "    train_data = dataset_paths[\"train4\"]\n",
        "    test_data = dataset_paths[\"test4\"]\n",
        "    directory = directory_dict[\"group4\"]\n",
        "  return num_classes, train_data, test_data, directory\n"
      ],
      "metadata": {
        "id": "HpbnxBXdK0KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes, train_datapath, test_datapath, directory = get_group_args(1)\n",
        "                                                # CHANGE THIS NUMBER ONLY WHEN SWITCHING GROUPS"
      ],
      "metadata": {
        "id": "bDOKiBBXLfJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# ======================= LOAD DATASETS =======================\n",
        "# load train set\n",
        "train_dataset = tf.data.Dataset.load(train_datapath)\n",
        "                                      # change train1 to other keys in dataset_paths\n",
        "\n",
        "# load test set\n",
        "test_dataset = tf.data.Dataset.load(test_datapath)\n",
        "                                      # change test1 to other keys\n",
        "\n",
        "# # uncomment to see shapes:\n",
        "# for item in train_dataset.take(5):\n",
        "#   print(item[0].shape)\n",
        "#   print(item[1].shape)\n",
        "\n",
        "# ^^ MICHELLE ADDED THE ABOVE LINES 5/2; DID NOT CHANGE BELOW\n",
        "# ============================================================\n",
        "# batching\n",
        "batch_size = 256\n",
        "train_dataset1 = train_dataset.batch(batch_size)\n",
        "train_dataset1 = train_dataset1.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "test_dataset=test_dataset.batch(batch_size)\n",
        "test_dataset1 = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(len(train_dataset1))\n",
        "#print(num_classes)\n",
        "print(len(test_dataset1))\n",
        "#print(num_classes_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzDhvtVd2ufJ",
        "outputId": "4fd6943e-aa4f-44e2-e8e0-1cc2e699de34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual\n",
        "\n",
        "The functionality of a residual block typically found in ResNet architectures. It includes convolutional layers, batch normalization, and possible adjustments in dimensions through 1x1 convolutions and stride alterations."
      ],
      "metadata": {
        "id": "B4J9m3OuxJMq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4pOT0DPrMpo"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import sys\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser\n",
        "parser = argparse.ArgumentParser(description='Train on HUST-OBS')\n",
        "\n",
        "# Add expected arguments\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float, metavar='LR', help='initial learning rate', dest='lr')\n",
        "parser.add_argument('--epochs', default=50, type=int, metavar='N', help='number of total epochs to run')\n",
        "parser.add_argument('--batch_size', default=256.0, type=float, metavar='N', help='mini-batch size')\n",
        "parser.add_argument('--num_workers', default=24.0, type=float)\n",
        "parser.add_argument('--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
        "# parser.add_argument('--results_dir', default='output', type=str, metavar='PATH', help='path to cache (default: none)')\n",
        "parser.add_argument('--checkpoint_freq', type=int, default=5)\n",
        "parser.add_argument('--seed', type=int, default=42)\n",
        "\n",
        "# Check if the code is running in the IPython environment\n",
        "if 'ipykernel' in sys.modules:\n",
        "    # Assume a default setup; modify as needed or determine a way to set these via the notebook interface\n",
        "    args = parser.parse_args(args=[])\n",
        "else:\n",
        "    args = parser.parse_args()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
        "\n",
        "# Make results directory if it doesn't exist\n",
        "# if args.results_dir == '':\n",
        "#     args.results_dir = './cache-' + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJADSLZrvDbQ",
        "outputId": "a68b52da-b7e5-4e05-c25a-97875a250cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(lr=0.001, epochs=50, batch_size=256.0, num_workers=24.0, wd=0.0005, resume='', checkpoint_freq=5, seed=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_channels, min_channels, num_channels,\n",
        "                 use_1x1conv=False, strides=1):\n",
        "        super(Residual, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(min_channels, kernel_size=1)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(min_channels, kernel_size=3, padding='valid', strides=strides)\n",
        "        self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1)\n",
        "\n",
        "        if use_1x1conv:\n",
        "            self.conv4 = tf.keras.layers.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
        "        else:\n",
        "            self.conv4 = None\n",
        "\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        X = inputs\n",
        "        Y = tf.nn.relu(self.bn1(self.conv1(X), training=training))\n",
        "        paddings = tf.constant([[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "        Y = tf.pad(Y, paddings)\n",
        "        Y = self.bn2(self.conv2(Y), training=training)\n",
        "        Y = self.bn3(self.conv3(Y), training=training)\n",
        "\n",
        "        if self.conv4:\n",
        "            X = self.conv4(X)\n",
        "\n",
        "        return tf.nn.relu(Y + X)"
      ],
      "metadata": {
        "id": "btNN9iMHvCf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InitialBlock\n",
        "\n",
        "This constructs the very first layers of the network which are crucial for reducing spatial dimensions and increasing depth (number of channels) before entering the main residual blocks."
      ],
      "metadata": {
        "id": "VI3vZDmFyBNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial block with convolution, batch norm, ReLU, and max pooling\n",
        "class InitialBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(InitialBlock, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='valid')\n",
        "        #valid padding with additional pads before to be equiv to nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "        self.pool = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='valid')\n",
        "        #valid padding with additional pads before to be equiv to nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        paddings = tf.constant([[0, 0], [3, 3], [3, 3], [0, 0]])\n",
        "        inputs = tf.pad(inputs, paddings)\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x, training=training)\n",
        "        x = self.relu(x)\n",
        "        pool_paddings = tf.constant([[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "        x = tf.pad(x, pool_paddings)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "x_vv9A_JxyP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Block Function\n",
        "This function uses the Residual class to construct sequences of residual blocks, which are the core components of ResNet architectures. It organizes these blocks based on their position in the network, adjusting their properties for downsampling or maintaining dimensionality where necessary."
      ],
      "metadata": {
        "id": "lFj898NuyLL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_block(input_channels, min_channels, num_channels, num_residuals, stride,\n",
        "                 first_block=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i == 0 and not first_block:\n",
        "            blk.append(Residual(input_channels, min_channels, num_channels,\n",
        "                                use_1x1conv=True, strides=stride))\n",
        "        elif i == 0 and first_block:\n",
        "            blk.append(Residual(input_channels, min_channels, num_channels, use_1x1conv=True))\n",
        "        else:\n",
        "            blk.append(Residual(num_channels, min_channels, num_channels))\n",
        "    return blk"
      ],
      "metadata": {
        "id": "GAeAqCCYtoqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MyResNet50\n",
        "\n",
        "This class integrates all previously defined components into a complete network. It uses the InitialBlock to process the input initially, then sequentially passes the data through multiple resnet_block sequences to form the deep architecture typical of ResNets. It concludes with global average pooling and a fully connected layer to produce the final output."
      ],
      "metadata": {
        "id": "AsijGx_PyUvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyResNet50(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyResNet50, self).__init__()\n",
        "        self.b1 = InitialBlock()\n",
        "        self.b2 = tf.keras.Sequential(resnet_block(64, 64, 256, 3, 2, first_block=True))\n",
        "        self.b3 = tf.keras.Sequential(resnet_block(256, 128, 512, 4, 2))\n",
        "        self.b4 = tf.keras.Sequential(resnet_block(512, 256, 1024, 6, 2))\n",
        "        self.b5 = tf.keras.Sequential(resnet_block(1024, 512, 2048, 2, 2))\n",
        "\n",
        "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc = tf.keras.layers.Dense(num_classes) #needs to be changed based on the train set's num classes\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.b1(inputs, training=training)\n",
        "        x = self.b2(x, training=training)\n",
        "        x = self.b3(x, training=training)\n",
        "        x = self.b4(x, training=training)\n",
        "        x = self.b5(x, training=training)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "59wlwkMWx9D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight Initialization"
      ],
      "metadata": {
        "id": "ZVziKQtOypa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight Initialization\n",
        "model = MyResNet50()\n",
        "model.build((batch_size, 128, 128, 3))  # Assuming input images are 128x128 with 3 channels\n",
        "model.summary()\n",
        "initializer = tf.keras.initializers.GlorotUniform()\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n",
        "        layer.kernel_initializer = initializer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAPTAqPtueB3",
        "outputId": "ff598447-a990-4079-fcdd-b687094a3eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_res_net50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " initial_block (InitialBloc  multiple                  9728      \n",
            " k)                                                              \n",
            "                                                                 \n",
            " sequential (Sequential)     (256, 32, 32, 256)        219008    \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (256, 16, 16, 512)        1228288   \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (256, 8, 8, 1024)         7124992   \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (256, 4, 4, 2048)         10518528  \n",
            "                                                                 \n",
            " global_average_pooling2d (  multiple                  0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " flatten (Flatten)           multiple                  0         \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  3641073   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22741617 (86.75 MB)\n",
            "Trainable params: 22702321 (86.60 MB)\n",
            "Non-trainable params: 39296 (153.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjusting Learning Rate Based on Schedule"
      ],
      "metadata": {
        "id": "l-2Dy1AIy2uD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removed because we are using Adam, which is already able to dynamically change the learning rate."
      ],
      "metadata": {
        "id": "yHSIFrL9NMHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "#     def __init__(self, initial_lr, total_epochs):\n",
        "#         super().__init__()\n",
        "#         self.initial_lr = tf.constant(initial_lr, dtype=tf.float32)\n",
        "#         self.total_epochs = tf.constant(total_epochs, dtype=tf.float32)  # Ensure total_epochs is also a float\n",
        "#         self.pi = tf.constant(math.pi, dtype=tf.float32)\n",
        "\n",
        "#     def __call__(self, step):\n",
        "#         step = tf.cast(step, tf.float32)  # Ensure step is treated as float\n",
        "#         return self.initial_lr * 0.5 * (1 + tf.cos(self.pi * step / self.total_epochs))\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "ag81io91y2KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy"
      ],
      "metadata": {
        "id": "tk1ysMHazAvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    predicted_indices = tf.argmax(y_pred, axis=1)\n",
        "    true_indices = tf.argmax(y_true, axis=1)  # Assuming y_true is one-hot encoded\n",
        "    correct_predictions = tf.equal(predicted_indices, true_indices)\n",
        "    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
      ],
      "metadata": {
        "id": "ftttKfwczCdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "9q-LX3G2zK1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def apply_grads(opt, grads, tv):\n",
        "    opt.apply_gradients(zip(grads, tv))\n",
        "\n",
        "def train_step(model, images, labels, loss_fn, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_fn(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    apply_grads(optimizer, gradients, model.trainable_variables)\n",
        "    acc = accuracy(predictions, labels)\n",
        "    return tf.cast(loss, tf.float32), tf.cast(acc, tf.float32)\n",
        "\n",
        "def train(model, data_loader, optimizer, epoch, initial_lr, total_epochs, loss_fn):\n",
        "    #optimizer.learning_rate = CustomCosineDecay(initial_lr, total_epochs)  # Adjust learning rate\n",
        "    #optimizer.learning_rate = cos_decay(epoch)  # Adjust learning rate\n",
        "    total_loss, total_num, trainacc = 0.0, 0.0, 0.0\n",
        "    train_bar = tqdm(data_loader, ncols=100)\n",
        "    for images, labels in train_bar:\n",
        "        if images.shape[0] != labels.shape[0]:\n",
        "          print(f\"Shape mismatch: {images.shape} vs {labels.shape}\")\n",
        "          continue  # Skip this batch or handle error\n",
        "        if images.shape[0] == 0:\n",
        "            print(\"Warning: Received an empty batch of images.\")\n",
        "            continue\n",
        "        if labels.shape[0] == 0:\n",
        "            print(\"Warning: Received an empty batch of labels.\")\n",
        "            continue\n",
        "        loss, acc = train_step(model, images, labels, loss_fn, optimizer)\n",
        "        batch_size = tf.cast(tf.shape(images)[0], tf.float32)  # Ensure it's float\n",
        "        if batch_size == 0:\n",
        "            print(\"Warning: Batch size is zero.\")\n",
        "            continue\n",
        "        trainacc += acc * batch_size\n",
        "        total_num += batch_size\n",
        "        total_loss += loss * batch_size\n",
        "        train_bar.set_description(\n",
        "            f'Train Epoch: [{epoch}/{total_epochs}], Loss: {total_loss / total_num:.4f}, trainacc: {trainacc / total_num:.6f}')\n",
        "\n",
        "    return total_loss / total_num, trainacc / total_num\n",
        "#optimizer = tf.keras.optimizers.SGD(learning_rate=CustomCosineDecay(args.lr, args.epochs), momentum=0.9)\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=CustomCosineDecay(args.lr, args.epochs))\n",
        "optimizer = tf.keras.optimizers.Adam(args.lr)"
      ],
      "metadata": {
        "id": "icASGF3QzEAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "qFK7Awn3zU9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_data_loader, epoch, total_epochs):\n",
        "    testacc, total_num, test_bar = 0.0, 0, tqdm(test_data_loader)\n",
        "    for image, label in test_bar:\n",
        "        predictions = model(image, training=False)\n",
        "        acc = accuracy(predictions, label)\n",
        "        total_num += image.shape[0]\n",
        "        testacc += acc * image.shape[0]\n",
        "        test_bar.set_description(\n",
        "            f'Test Epoch: [{epoch}/{total_epochs}], testacc: {testacc / total_num:.6f}')\n",
        "    return testacc / total_num"
      ],
      "metadata": {
        "id": "so8iE2kwzXRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing On Picture"
      ],
      "metadata": {
        "id": "IkHrPNmzCSFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results dictionary to store metrics\n",
        "# results = {'train_loss': [], 'train_acc': [], 'test_acc': [], 'lr': []}\n",
        "results = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
        "epoch_start = 1\n",
        "\n",
        "# Load model and optimizer states if resuming from a checkpoint\n",
        "if args.resume:\n",
        "    checkpoint = tf.train.Checkpoint(model, optimizer=optimizer)\n",
        "    status = checkpoint.restore(tf.train.latest_checkpoint(args.resume))\n",
        "    status.assert_existing_objects_matched()\n",
        "    #epoch_start = ?\n",
        "    print(f'Loaded from: {args.resume}')\n",
        "else:\n",
        "    # If not resuming, initialize weights\n",
        "    model.build((batch_size, 128, 128, 3))  # Assuming input images are 128x128 with 3 channels\n",
        "    initializer = tf.keras.initializers.GlorotUniform()\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "            layer.kernel_initializer = initializer\n",
        "            if hasattr(layer, 'kernel'):\n",
        "                layer.kernel.assign(initializer(shape=layer.kernel.shape))\n",
        "\n",
        "# Ensure the results directory exists\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "# Save arguments to a JSON file\n",
        "with open(os.path.join(directory, 'args.json'), 'w') as fid:\n",
        "    json.dump(vars(args), fid, indent=2)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epoch_start, args.epochs + 1):\n",
        "    train_loss, train_acc = train(model, train_dataset1, optimizer, epoch, args.lr, args.epochs,loss_fn)\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    test_acc = test(model, test_dataset1, epoch,args.epochs)\n",
        "    results['test_acc'].append(test_acc)\n",
        "    #current_lr = args.lr * 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
        "    #results['lr'].append(current_lr)\n",
        "    #optimizer.lr.assign(current_lr)  # Adjust learning rate\n",
        "\n",
        "    # Save statistics to CSV\n",
        "    data_frame = pd.DataFrame(data=results, index=range(epoch_start, epoch + 1))\n",
        "    data_frame.to_csv(os.path.join(directory, 'log.csv'), index_label='epoch')\n",
        "\n",
        "    # Save checkpoints at specified frequency\n",
        "    if epoch % args.checkpoint_freq == 0:\n",
        "        checkpoint_path = os.path.join(directory, f'checkpoint_ep{epoch:04}.ckpt')\n",
        "        checkpoint = tf.train.Checkpoint(model, optimizer=optimizer, epoch=tf.Variable(epoch))\n",
        "        checkpoint.save(file_prefix=checkpoint_path)\n",
        "\n",
        "print('Training complete')"
      ],
      "metadata": {
        "id": "KGqtEDG1CWlw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9aab8ff7-2837-4a0b-8332-8b10736666e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: [1/50], Loss: 7.1725, trainacc: 0.006184: 100%|██████| 238/238 [03:16<00:00,  1.21it/s]\n",
            "Test Epoch: [1/50], testacc: 0.001600: 100%|██████████| 64/64 [01:21<00:00,  1.28s/it]\n",
            "Train Epoch: [2/50], Loss: 6.4963, trainacc: 0.012927: 100%|██████| 238/238 [01:52<00:00,  2.12it/s]\n",
            "Test Epoch: [2/50], testacc: 0.001846: 100%|██████████| 64/64 [00:19<00:00,  3.30it/s]\n",
            "Train Epoch: [3/50], Loss: 5.6665, trainacc: 0.033928: 100%|██████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [3/50], testacc: 0.006583: 100%|██████████| 64/64 [00:20<00:00,  3.14it/s]\n",
            "Train Epoch: [4/50], Loss: 4.7619, trainacc: 0.091358: 100%|██████| 238/238 [01:59<00:00,  1.99it/s]\n",
            "Test Epoch: [4/50], testacc: 0.006214: 100%|██████████| 64/64 [00:19<00:00,  3.26it/s]\n",
            "Train Epoch: [5/50], Loss: 3.9056, trainacc: 0.191695: 100%|██████| 238/238 [01:52<00:00,  2.11it/s]\n",
            "Test Epoch: [5/50], testacc: 0.029285: 100%|██████████| 64/64 [00:20<00:00,  3.19it/s]\n",
            "Train Epoch: [6/50], Loss: 3.1922, trainacc: 0.306883: 100%|██████| 238/238 [01:48<00:00,  2.19it/s]\n",
            "Test Epoch: [6/50], testacc: 0.069521: 100%|██████████| 64/64 [00:19<00:00,  3.35it/s]\n",
            "Train Epoch: [7/50], Loss: 2.5996, trainacc: 0.415969: 100%|██████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [7/50], testacc: 0.143718: 100%|██████████| 64/64 [00:20<00:00,  3.17it/s]\n",
            "Train Epoch: [8/50], Loss: 2.0427, trainacc: 0.528707: 100%|██████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [8/50], testacc: 0.274394: 100%|██████████| 64/64 [00:20<00:00,  3.12it/s]\n",
            "Train Epoch: [9/50], Loss: 1.6662, trainacc: 0.606019: 100%|██████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [9/50], testacc: 0.016611: 100%|██████████| 64/64 [00:20<00:00,  3.12it/s]\n",
            "Train Epoch: [10/50], Loss: 1.4040, trainacc: 0.659469: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [10/50], testacc: 0.344408: 100%|██████████| 64/64 [00:19<00:00,  3.26it/s]\n",
            "Train Epoch: [11/50], Loss: 1.2040, trainacc: 0.699975: 100%|█████| 238/238 [01:50<00:00,  2.15it/s]\n",
            "Test Epoch: [11/50], testacc: 0.394303: 100%|██████████| 64/64 [00:20<00:00,  3.07it/s]\n",
            "Train Epoch: [12/50], Loss: 1.0482, trainacc: 0.730713: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [12/50], testacc: 0.462717: 100%|██████████| 64/64 [00:20<00:00,  3.14it/s]\n",
            "Train Epoch: [13/50], Loss: 0.9190, trainacc: 0.762059: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [13/50], testacc: 0.327366: 100%|██████████| 64/64 [00:19<00:00,  3.29it/s]\n",
            "Train Epoch: [14/50], Loss: 0.7969, trainacc: 0.787863: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [14/50], testacc: 0.396579: 100%|██████████| 64/64 [00:19<00:00,  3.21it/s]\n",
            "Train Epoch: [15/50], Loss: 0.6951, trainacc: 0.811611: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [15/50], testacc: 0.374800: 100%|██████████| 64/64 [00:20<00:00,  3.13it/s]\n",
            "Train Epoch: [16/50], Loss: 0.5967, trainacc: 0.834783: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [16/50], testacc: 0.364895: 100%|██████████| 64/64 [00:19<00:00,  3.22it/s]\n",
            "Train Epoch: [17/50], Loss: 0.5138, trainacc: 0.856328: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [17/50], testacc: 0.113080: 100%|██████████| 64/64 [00:20<00:00,  3.12it/s]\n",
            "Train Epoch: [18/50], Loss: 0.4570, trainacc: 0.870044: 100%|█████| 238/238 [01:54<00:00,  2.08it/s]\n",
            "Test Epoch: [18/50], testacc: 0.054817: 100%|██████████| 64/64 [00:40<00:00,  1.56it/s]\n",
            "Train Epoch: [19/50], Loss: 0.4125, trainacc: 0.877938: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [19/50], testacc: 0.071429: 100%|██████████| 64/64 [00:19<00:00,  3.22it/s]\n",
            "Train Epoch: [20/50], Loss: 0.3680, trainacc: 0.891243: 100%|█████| 238/238 [01:53<00:00,  2.09it/s]\n",
            "Test Epoch: [20/50], testacc: 0.085333: 100%|██████████| 64/64 [00:40<00:00,  1.56it/s]\n",
            "Train Epoch: [21/50], Loss: 0.3189, trainacc: 0.904843: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [21/50], testacc: 0.048050: 100%|██████████| 64/64 [00:19<00:00,  3.24it/s]\n",
            "Train Epoch: [22/50], Loss: 0.2770, trainacc: 0.915599: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [22/50], testacc: 0.473299: 100%|██████████| 64/64 [00:20<00:00,  3.12it/s]\n",
            "Train Epoch: [23/50], Loss: 0.2376, trainacc: 0.928032: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [23/50], testacc: 0.496862: 100%|██████████| 64/64 [00:40<00:00,  1.56it/s]\n",
            "Train Epoch: [24/50], Loss: 0.2161, trainacc: 0.935334: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [24/50], testacc: 0.145380: 100%|██████████| 64/64 [00:40<00:00,  1.56it/s]\n",
            "Train Epoch: [25/50], Loss: 0.1907, trainacc: 0.940679: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [25/50], testacc: 0.511013: 100%|██████████| 64/64 [00:21<00:00,  3.02it/s]\n",
            "Train Epoch: [26/50], Loss: 0.1692, trainacc: 0.948442: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [26/50], testacc: 0.280362: 100%|██████████| 64/64 [00:40<00:00,  1.56it/s]\n",
            "Train Epoch: [27/50], Loss: 0.1514, trainacc: 0.953935: 100%|█████| 238/238 [01:48<00:00,  2.18it/s]\n",
            "Test Epoch: [27/50], testacc: 0.054510: 100%|██████████| 64/64 [00:40<00:00,  1.56it/s]\n",
            "Train Epoch: [28/50], Loss: 0.1380, trainacc: 0.957355: 100%|█████| 238/238 [01:49<00:00,  2.18it/s]\n",
            "Test Epoch: [28/50], testacc: 0.523133: 100%|██████████| 64/64 [00:20<00:00,  3.16it/s]\n",
            "Train Epoch: [29/50], Loss: 0.1401, trainacc: 0.957191: 100%|█████| 238/238 [02:21<00:00,  1.68it/s]\n",
            "Test Epoch: [29/50], testacc: 0.271502: 100%|██████████| 64/64 [00:20<00:00,  3.12it/s]\n",
            "Train Epoch: [30/50], Loss: 0.1231, trainacc: 0.962191: 100%|█████| 238/238 [01:47<00:00,  2.21it/s]\n",
            "Test Epoch: [30/50], testacc: 0.509167: 100%|██████████| 64/64 [00:21<00:00,  2.98it/s]\n",
            "Train Epoch: [31/50], Loss: 0.1163, trainacc: 0.964559: 100%|█████| 238/238 [01:49<00:00,  2.17it/s]\n",
            "Test Epoch: [31/50], testacc: 0.464255: 100%|██████████| 64/64 [00:20<00:00,  3.06it/s]\n",
            "Train Epoch: [32/50], Loss: 0.1092, trainacc: 0.966400:  50%|██▍  | 118/238 [01:21<01:23,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0d8c4e55a751>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-c8928e5f90d2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, epoch, initial_lr, total_epochs, loss_fn)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning: Received an empty batch of labels.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it's float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-c8928e5f90d2>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, images, labels, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b6c9280ece48>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \"\"\"\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1869688a9035>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             outputs = self._fused_batch_norm(\n\u001b[0m\u001b[1;32m    598\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    988\u001b[0m             )\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         output, mean, variance = control_flow_util.smart_cond(\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fused_batch_norm_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fused_batch_norm_inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m             return tf.compat.v1.nn.fused_batch_norm(\n\u001b[0m\u001b[1;32m    965\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m   y, running_mean, running_var, _, _, _ = gen_nn_ops.fused_batch_norm_v3(\n\u001b[0m\u001b[1;32m   1581\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m       \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   5173\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5175\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   5176\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5177\u001b[0m         \u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exponential_avg_factor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexponential_avg_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}