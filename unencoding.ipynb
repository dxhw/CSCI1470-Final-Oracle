{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for the purpose of undoing the one hot encoding so that we can determine the original character IDs being mapped to in visualization.ipynb"
      ],
      "metadata": {
        "id": "KSTfiGKD9saa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3lTv3w2SLoK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18d373f-9ba0-47dd-a47c-d19a33315fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Z9poxyeX-aaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWvoogATLjyF"
      },
      "outputs": [],
      "source": [
        "# dict contains file paths to tensorflow datasets created using preprocessing code\n",
        "saved_data_paths = {\n",
        "    \"mock\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/mock\",\n",
        "    \"test4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/wangtest\",\n",
        "    \"wangtrain\":\"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/wangtrain\",\n",
        "    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1\",\n",
        "    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2\",\n",
        "    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3\",\n",
        "\n",
        "    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test1\",\n",
        "    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test2\",\n",
        "    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/test3\",\n",
        "\n",
        "    \"train1a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1a\",\n",
        "    \"train1b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1b\",\n",
        "    \"train1c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train1c\",\n",
        "\n",
        "    \"train2a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2a\",\n",
        "    \"train2b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2b\",\n",
        "    \"train2c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train2c\",\n",
        "\n",
        "    \"train3a\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3a\",\n",
        "    \"train3b\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3b\",\n",
        "    \"train3c\": \"/content/drive/Shareddrives/DL_Final_Project/tf_datasets/train3c\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paths to save onehot datasets to:\n",
        "onehot_datapaths = {\n",
        "    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/test1\",\n",
        "    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/test2\",\n",
        "    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/test3\",\n",
        "    \"test4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/test4\",\n",
        "\n",
        "    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/train1\",\n",
        "    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/train2\",\n",
        "    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/train3\",\n",
        "    \"train4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot/train3\"\n",
        "}"
      ],
      "metadata": {
        "id": "iQ3jTvm8MAxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paths to save onehot datasets to:\n",
        "onehot_datapaths2 = {\n",
        "    \"test1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test1\",\n",
        "    \"test2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test2\",\n",
        "    \"test3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test3\",\n",
        "    \"test4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/test4\",\n",
        "\n",
        "    \"train1\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train1\",\n",
        "    \"train2\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train2\",\n",
        "    \"train3\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train3\",\n",
        "    \"train4\": \"/content/drive/Shareddrives/DL_Final_Project/tf_data_onehot2/train4\"\n",
        "}"
      ],
      "metadata": {
        "id": "FdOtb2oHFHOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_name: str):\n",
        "  path = saved_data_paths[dataset_name]\n",
        "  dataset = tf.data.Dataset.load(path)\n",
        "  print(\"Dataset\", dataset_name, \"loaded\")\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "83S8fjv24b_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes_dict = {\n",
        "    \"train1\": 1777,\n",
        "    \"train2\": 1656,\n",
        "    \"train3\": 1628,\n",
        "    \"train4\": 1588\n",
        "}"
      ],
      "metadata": {
        "id": "E2wwKTwUEUoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_labels(labels, num_classes):\n",
        "    # Get unique labels and number of classes\n",
        "    unique_labels = sorted(set(labels))\n",
        "\n",
        "    # Map each unique label to an integer in the range [0, num_classes - 1]\n",
        "    label_map = {index: str(label) for index, label in enumerate(unique_labels)}\n",
        "\n",
        "    print(\"Labels transformed\")\n",
        "    return label_map"
      ],
      "metadata": {
        "id": "3yICfbc1sz3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dict(dataset):\n",
        "    label_one_hot_dict = {}\n",
        "    labels = []\n",
        "    for item in tqdm(dataset):\n",
        "        _, label = item\n",
        "        labels.append(label.numpy())\n",
        "\n",
        "    num_classes = 1628\n",
        "    transformed_label_dict = transform_labels(labels, num_classes)\n",
        "    return transformed_label_dict"
      ],
      "metadata": {
        "id": "J-nj5WhcPxZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.load(\"/content/drive/Shareddrives/DL_Final_Project/concat_datasets/train3\")"
      ],
      "metadata": {
        "id": "RKc8bLvkQsEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = get_dict(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSsj0F9WRfYe",
        "outputId": "a6005572-b514-472b-9ef2-609b475f86b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65757/65757 [02:17<00:00, 477.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change to predicted labels\n",
        "predicted_labels = [377, 1311,  334,  787, 1251]"
      ],
      "metadata": {
        "id": "p14rzOCAZsc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([label_dict[label] for label in predicted_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow7SMTqbTWUV",
        "outputId": "8bb23eae-86b4-42ff-dd17-c3696c020f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['413', '1422', '365', '841', '1349']\n"
          ]
        }
      ]
    }
  ]
}